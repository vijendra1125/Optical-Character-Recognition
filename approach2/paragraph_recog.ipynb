{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"paragraph_recog.ipynb","version":"0.3.2","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"SBpaJ9JWrvFO","colab_type":"text"},"cell_type":"markdown","source":["# **Libraries**"]},{"metadata":{"id":"XIXWISTSZCeR","colab_type":"code","colab":{}},"cell_type":"code","source":["import cv2\n","from PIL import ImageFont, ImageDraw, Image \n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","from datetime import datetime as dt\n","import tensorflow as tf\n","import string\n","\n","bold = '\\033[1m'\n","end = '\\033[0m'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sgcoJqMgrq6Z","colab_type":"text"},"cell_type":"markdown","source":["# **Functions**"]},{"metadata":{"id":"1TRhUWcdZEof","colab_type":"code","colab":{}},"cell_type":"code","source":["def variable(name,shape,initializer,weight_decay = None):\n","  '''\n","  create parameter tensor\n","  '''\n","  var = tf.get_variable(name, shape, initializer = initializer)\n","  if weight_decay is not None:\n","    weight_loss = tf.multiply(tf.nn.l2_loss(var),weight_decay, name=\"weight_loss\")\n","    tf.add_to_collection('losses', weight_loss)\n","  return var\n","\n","\n","#need to customize activation and lrn\n","def conv_block(block_num,\n","               input_data,\n","               weights, \n","               weight_initializer=tf.contrib.layers.xavier_initializer(),\n","               bias_initializer=tf.constant_initializer(0.0),\n","               conv_op=[1,1,1,1],\n","               conv_padding='SAME',\n","               weight_decay=None,\n","               lrn=True,\n","               dropout=1.0, \n","               activation=True):\n","  '''\n","  convolutional block\n","  '''\n","  with tf.variable_scope('conv'+ str(block_num), reuse = tf.AUTO_REUSE) as scope:\n","    input_data = tf.nn.dropout(input_data, dropout)\n","    kernel = variable('weights', weights, initializer = weight_initializer, weight_decay = weight_decay)\n","    biases = variable('biases', weights[3], initializer=bias_initializer, weight_decay=None)\n","    conv = tf.nn.conv2d(input_data, kernel, conv_op, padding=conv_padding)\n","    pre_activation = tf.nn.bias_add(conv, biases)\n","    if lrn==True:\n","      pre_activation = tf.nn.lrn(pre_activation, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,name='norm')\n","    if activation:\n","      conv_out = tf.nn.relu(pre_activation, name=scope.name)\n","      return conv_out\n","    else:\n","      return pre_activation\n","\n","\n","\n","def dense_block(block_num,\n","                input_data,\n","                neurons,\n","                weight_initializer=tf.contrib.layers.xavier_initializer(),\n","                bias_initializer=tf.constant_initializer(0.0),\n","                weight_decay=None,\n","                activation=True, \n","                dropout=1.0):\n","  '''\n","  Fully connected block\n","  '''\n","  with tf.variable_scope('dense'+ str(block_num), reuse = tf.AUTO_REUSE) as scope:\n","    input_data = tf.nn.dropout(input_data, dropout)\n","    weights = variable('weights', [input_data.shape[1], neurons], \\\n","                       initializer=weight_initializer, weight_decay = weight_decay)\n","    biases = variable('biases', [1,neurons], initializer = bias_initializer, weight_decay = None)\n","    dense = tf.matmul(input_data,weights)+biases\n","    if activation:\n","      dense=tf.nn.relu(dense, name=scope.name)\n","    return dense\n","\n","def decoding(encoded_data, type = 'logit'):\n","  prediction = np.argmax(encoded_data, 1)\n","  decoded_prediction = ''\n","  for dp in prediction:\n","    predicted_text = all_chr[dp]\n","    decoded_prediction += predicted_text\n","  return decoded_prediction"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yIkGNcOfrn3-","colab_type":"text"},"cell_type":"markdown","source":["# **Model**"]},{"metadata":{"id":"bi1iYAMMZOb8","colab_type":"code","colab":{}},"cell_type":"code","source":["def inference(image_batch, class_count, weights,\n","              dropout=[1,1,1,1,1,1,1,1],\n","              wd=None):\n","  '''\n","  Forward propagation\n","  '''\n","\n","  i = 0\n","           \n","  conv_op=[[1,1,1,1],[1,1,1,1],[1,1,1,1], [1,1,1,1]]\n","  \n","  conv1 = conv_block(1,image_batch,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n","  i=i+1\n","  pool1=tf.nn.max_pool(conv1, ksize=[1, 4, 4, 1], strides=[1,4,4,1],padding='SAME', name='pool1') #32x32\n","  \n","  conv2 = conv_block(2,pool1,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n","  i=i+1\n","  pool2=tf.nn.max_pool(conv2, ksize=[1, 4, 4, 1], strides=[1,4,4,1],padding='SAME', name='pool2') #8x8\n","  \n","  conv3 = conv_block(3,pool2,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n","  i=i+1\n","  pool3=tf.nn.max_pool(conv3, ksize=[1, 4, 4, 1], strides=[1,4,4,1],padding='SAME', name='pool3') #2x2\n","  \n","  conv4 = conv_block(4,pool3,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n","  i=i+1\n","  pool4=tf.nn.max_pool(conv4, ksize=[1, 2, 2, 1], strides=[1,2,2,1],padding='SAME', name='pool4')#1x1\n","\n","  flat=tf.reshape(pool4, [tf.shape(image_batch)[0], class_count], name='flat')\n","\t\t\n","  return flat"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TB2TsCWhrEXN","colab_type":"text"},"cell_type":"markdown","source":["# **function for image segmentation**"]},{"metadata":{"id":"awVhC8QErz01","colab_type":"code","colab":{}},"cell_type":"code","source":["def img_list(image_folder, image_name_list):\n","  list = []\n","  for il in image_name_list:\n","    image = cv2.imread(image_folder + il)\n","    plt.imshow(image)\n","    plt.show()\n","    list.append(image)\n","  return list\n","    \n","def show(inp, string =\"\"):\n","    print(string)\n","    if inp.shape !=3:\n","      plt.imshow(inp, cmap = 'gray')\n","    else:\n","      plt.imshow(inp)\n","    plt.show() \n","    print ()\n","    \n","def multi_show(inp, string=\"\", fig_size = (18,18), row = 10, col = 20):\n","  print(string)\n","  fig=plt.figure(figsize=fig_size)\n","  for i, r in enumerate(inp):\n","    fig.add_subplot(row,col, i+1)\n","    if r.shape !=3:\n","      plt.imshow(r, cmap = 'gray')\n","    else:\n","      plt.imshow(r)\n","  plt.show()\n","  print(len(inp))\n","  print()\n","  \n","def find_roi(inp_list, resize = None, thres = 127, \n","             d_kernel_size = (3, 3), e_kernel_size = (1,1), \n","             w_min = 100, w_max = 2000, h_min = 20, h_max = 1000,\n","             area_thres = 0.3, roi_resize = None, extra_pixel = 3, \n","             show_bool = True, dis_size=8, dis_row=10, dis_col=10, arrange = 0):\n","  all_inp = []\n","  for inp in inp_list:\n","    all_roi = []\n","    if len(inp.shape) == 3:\n","      #convert it to gray scale\n","      inp = cv2.cvtColor(inp,cv2.COLOR_BGR2GRAY) \n","      \n","    #resize image if needed\n","    if resize !=0: \n","      inp = cv2.resize(inp, (inp.shape[1]*resize,inp.shape[0]*resize))\n","     \n","    #perform thresholding\n","    if thres != None:\n","      _, inp = cv2.threshold(inp,thres,255,cv2.THRESH_BINARY_INV) \n","    \n","    #keep thresholded image in seperately\n","    inp_org = inp\n","    \n","    #kernel for erosion\n","    e_kernel = np.ones(e_kernel_size, np.uint8)\n","    #erode image\n","    inp = cv2.erode(inp, e_kernel, iterations=1)\n","    #kernel for dilation\n","    d_kernel = np.ones(d_kernel_size, np.uint8)\n","    #dilate image\n","    inp = cv2.dilate(inp, d_kernel, iterations=1) \n"," \n","    if show_bool == True:\n","      show(inp, \"dilated image\")\n","    \n","    #find contours\n","    _,ctrs,_ = cv2.findContours(inp.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) \n","    #sort contours\n","    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[arrange]) \n","    \n","    #dicard useless rois\n","    for i, ctr in enumerate(sorted_ctrs):\n","      discard = 0\n","      #get bounding box\n","      x, y, w, h = cv2.boundingRect(ctr) \n","      if w_min<w<w_max and h_min<h<h_max:\n","        \n","        for j, temp_ctrs in enumerate(sorted_ctrs):\n","              temp_x, temp_y, temp_w, temp_h = cv2.boundingRect(temp_ctrs)\n","            \n","              if j != i and temp_w <w_max and temp_h <h_max:\n","                \n","                #if there is overlap and intersection area is more than threshold then discard the bounding box\n","                 if (temp_x<x<temp_x+temp_w and temp_y<y<temp_y+temp_h) or (temp_x<x+w<temp_x+temp_w and temp_y<y+h<temp_y+temp_h):\n","                  dx = min((temp_x + temp_w),(x+w)) - max(temp_x, x)\n","                  dy = min((temp_y + temp_h),(y+h)) - max(temp_y, y)\n","                  if(dx*dy>0):\n","                    intersection_area = dx * dy\n","                  else:\n","                    intersection_area = 0\n","                  if (intersection_area/(w*h) > area_thres):\n","                    discard += 1\n","                    break\n","                    \n","        #if not discarded then add bounding box in list\n","        if discard == 0: \n","          roi = inp_org[y:y+h-extra_pixel, x:x+w] \n","          if roi_resize !=None:\n","            roi = cv2.resize(roi, roi_resize)\n","          all_roi.append(roi)\n","    \n","    if show_bool == True:\n","      multi_show(all_roi, \"all ROIs\",fig_size=(dis_size, dis_size), row=dis_row, col=dis_col)\n","    all_inp.append(all_roi)\n","#     print(len(all_roi))\n","  return all_inp"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-HX1HSLbr0a_","colab_type":"text"},"cell_type":"markdown","source":["# **Path and file name**"]},{"metadata":{"id":"3Li4FdL2EL5w","colab_type":"code","colab":{}},"cell_type":"code","source":["digit = '0 1 2 3 4 5 6 7 8 9 ' #all digits\n","lc = 'a b c d e f g h i j k l m n o p q r s t u v w x y z ' #all lower case\n","all_uc = 'A B C D E F G H I J K L M N O P Q R S T U V W X Y Z ' #all upper case\n","sel_uc = 'A B D E F G H J K L M N Q R T Y ' #selected upper case\n","all_sign = '''! @ # $ % ^ & ? / ( ) { } [ ] < > * - + = \\ : ; ' . ''' #all useful signs\n","sel_sign = '''. ( ) % ''' #selected signs\n","\n","\n","digi_perc = digit + '% ' #digits with percentage\n","\n","digi_lc = digit + lc #digits and all lower case\n","digi_uc = digit + all_uc #digits and all upper case\n","all_letters = lc + all_uc #all letters\n","digi_all_letters = digi_lc + all_letters #all digits and all letters\n","digi_all_letters_all_sign = digi_all_letters + all_sign #all digits, all letters and all useful signs\n","\n","lc_sel_uc = lc + sel_uc\n","digi_lc_sel_uc = digit + lc + sel_uc\n","digi_all_letters_sel_sign = digi_all_letters + sel_sign # all digit, all letters and selected signs\n","digi_lc_sel_uc_sel_sign = digi_lc + sel_uc + sel_sign # all digits, all lower case, selected upper case and selected signs\n","digi_lc_sel_uc_all_sign = digi_lc + sel_uc + all_sign # all digits, all lower case, selected upper case and all signs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QGs9K1cQZXoQ","colab_type":"code","colab":{}},"cell_type":"code","source":["path = \"drive/share/OCR/OCR:Part3/\"\n","\n","# digi, lc, sel uc\n","checkpoint_restore = path + \"checkpoints/checkpoint_digi_lc_sel_uc_sel_sign_1.ckpt\"\n","all_chr = digi_lc_sel_uc_sel_sign.replace(\" \", \"\")\n","class_count = 56\n","weights=[[3,3,1,16],\n","         [3,3,16,24],\n","         [3,3,24,42], \n","         [3,3,42,56]]\n","\n","test_file_path = path +\"test_images/\"\n","test_file_list = os.listdir(test_file_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ULzLKwHKr5BJ","colab_type":"text"},"cell_type":"markdown","source":["# **Load and segment data**"]},{"metadata":{"id":"k5fGVVCyIQ-Q","colab_type":"code","colab":{}},"cell_type":"code","source":["image_list = img_list(test_file_path, test_file_list)\n","    \n","# get the list of list for sentences of image in image list\n","sentences = find_roi(inp_list = image_list, resize = 10, thres = 157,\n","                 d_kernel_size = (25,150), e_kernel_size = (1,1),\n","                 w_min = 100, w_max = 20000, h_min = 20, h_max = 10000,\n","                 roi_resize = None, extra_pixel = 0, \n","                 show_bool = False, dis_size = 18, dis_row = 5, dis_col = 2, arrange = 1)\n","print(\"total number of images:\", len(sentences),'\\n') #[[]]\n","\n","all_words = []\n","for i in range(len(image_list)):\n","    print(\"total number of sentences in image\",i+1, ':', len(sentences[i]),'\\n')\n","    words = find_roi(inp_list = sentences[i], resize = 1, thres = None,\n","                   d_kernel_size = (15,45), e_kernel_size = (1,1),\n","                   w_min = 50, w_max = 2000, h_min = 10, h_max = 1000,\n","                   roi_resize = None, extra_pixel = 0, \n","                   show_bool = False, dis_size = 18, dis_row = 10, dis_col = 10)\n","    all_words.append(words) #[[[]]]\n","\n","all_characters = []    \n","for i in range(len(image_list)):\n","    characters_in_image = []\n","    for j in range(len(all_words[i])):\n","        print(\"total number of words in sentence\",j+1,'of image', i+1, ':', len(all_words[i][j]),'\\n')\n","        characters = find_roi(inp_list = all_words[i][j], resize = 1, thres = None,\n","                       d_kernel_size = (20,1), e_kernel_size = (1,1),\n","                       w_min = 10, w_max = 500, h_min = 30, h_max = 500,\n","                       roi_resize = (128,128), extra_pixel = 10, \n","                       show_bool = False, dis_size = 18, dis_row = 20, dis_col = 20)\n","        characters_in_image.append(characters)   \n","    all_characters.append(characters_in_image)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fxE5dxY-r_vF","colab_type":"text"},"cell_type":"markdown","source":["# **Prepare data for CNN**"]},{"metadata":{"id":"fBodsLpgaPwP","colab_type":"code","colab":{}},"cell_type":"code","source":["for im in all_characters:\n","  for k,s in enumerate(im):\n","    for j,w in enumerate(s):\n","      for i,ar in enumerate(w):\n","        w[i] = np.reshape(ar, (128,128,1))\n","      s[j] = np.float32(np.array(w))\n","    im[k] = np.array(s)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lRVrNHD0sFnT","colab_type":"text"},"cell_type":"markdown","source":["# **Feed data to CNN and predict**"]},{"metadata":{"id":"Lkdmaw6wbc4q","colab_type":"code","colab":{}},"cell_type":"code","source":["X=tf.placeholder(\"float32\",[None,128,128,1])\n","decoded_text = []\n","logit = inference(X, class_count, weights)\n","init=tf.global_variables_initializer()\n","saver=tf.train.Saver()\n","\n","with tf.Session() as sess:\n","  sess.run(tf.global_variables_initializer())\n","  sess.run(tf.local_variables_initializer())\n","  saver.restore(sess,checkpoint_restore)\n","  ax = plt.gca()\n","  fig = plt.gcf()\n","  for i,im in enumerate(all_characters):\n","      print(\"=================================\")\n","      print(bold + \"~~~~~given image\", i+1, '~~~~~~')\n","      ax = plt.gca()\n","      fig = plt.gcf()\n","      fig.set_size_inches(12, 7)\n","      plt.axis('off')\n","      ax.grid(False)\n","      plt.imshow(image_list[i])\n","      plt.show()  \n","      print(bold + \"~~~~~predicted text~~~~~\\n\", end = '')\n","      for s in im:\n","        for w in s:\n","#           print(len(w))\n","          text = logit.eval({X:w})\n","          decoded_text = decoding(text, type = 'logit')\n","          print(str(decoded_text), end = ' ')\n","        print()\n","      print(\"\\n=================================\\n\\n\\n\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LNKxBWqDnA-O","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}