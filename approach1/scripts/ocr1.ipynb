{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OCR using CNN.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{},"source":["# About OCR approach1:\n","Through ocr1.py script we are targeting to train a small Convolutional Neurl Network (CNN)  with the data we generated using random_string_data_gen.py. Network should be able to recognize the random string in a given image and provide it as ouput.  \n","In the first phase we will be testing it using generated data itself whereas later we try to crop some image from our screen meeting dataset contrain and see how well network works.  \n","Link to blog: https://medium.com/@vijendra1125/ocr-part-2-ocr-using-cnn-f43f0cee8016"],"execution_count":null,"outputs":[]},{"metadata":{"id":"HqYb5NXVDdSN","colab_type":"text"},"cell_type":"markdown","source":["## Load Libraries"],"execution_count":null,"outputs":[]},{"metadata":{"id":"SOtEHEKq_hWe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import os\n","from datetime import datetime as dt\n","import string\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import tensorflow as tf\n","\n","from ocr1_functions import *\n","\n","# set ro print numpy array without truncation\n","np.set_printoptions(threshold=sys.maxsize)\n","\n","bold = '\\033[1m'\n","end = '\\033[0m'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Parameters"],"execution_count":null,"outputs":[]},{"metadata":{"id":"y6J1kZAECcXE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["## paths ##\n","# path to folder where data (tfrecord) files has been stored\n","folder_path = \"../data\"\n","# path to load checkpoint\n","checkpoint_restore = \"../cp/ocr1_3to8\"\n","# path to save checkpoint \n","checkpoint_save = \"../cp/ocr1_3to8\"\n","\n","## data realted params ##\n","# train and test file paths\n","filenames = os.listdir(folder_path)\n","train_file_paths = []\n","test_file_paths = []\n","for filename in filenames:\n","    if \"train\" in filename:\n","        train_file_paths.append(os.path.join(folder_path, filename))\n","    elif \"test\" in filename:\n","        test_file_paths.append(os.path.join(folder_path, filename))\n","# total number of data in each train tfrecord\n","# data_per_train_file = 8192\n","total number of data in each test tfrecord\n","data_per_test_file = 2048\n","# image size\n","image_size = [32,256,1]\n","# total numember of classes\n","class_count = 63\n","# string length (including whitespace)\n","string_length = 16\n","\n","## training  setup related params ##\n","# restore from given checkpoint\n","restore = False\n","# dropout for each layer (1 means no drop)\n","dropout = [1, 1, 1, 1]\n","# weight decay\n","wd = 0.000\n","# learning rafe\n","lr = 0.01\n","# batch size\n","# batch_size = 32\n","batch_size = 1\n","# total number of epochs\n","epochs = 5\n","# after every x epoch decrease learning rate by factor of y (var_lr = [x, y])\n","var_lr=[None,None]\n","# parameters related to reading tfrecord\n","num_of_threads=16\n","min_after_dequeue=5000\n","capacity=min_after_dequeue+(num_of_threads+1)*batch_size"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Train"],"execution_count":null,"outputs":[]},{"metadata":{"id":"uXtfaRdjDOBK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":714},"outputId":"21d63f3b-80dd-4ed2-d51a-cd5e63e2cbfe","executionInfo":{"status":"ok","timestamp":1532018515949,"user_tz":-330,"elapsed":434949,"user":{"displayName":"Vijendra Singh","photoUrl":"//lh3.googleusercontent.com/-NdZ5dixuTHU/AAAAAAAAAAI/AAAAAAAArI4/R6qZstWMpR4/s50-c-k-no/photo.jpg","userId":"111198229299491674196"}}},"cell_type":"code","source":["# data count\n","train_data_count = data_per_train_file * len(train_file_paths)\n","test_data_count = data_per_test_file * len(test_file_paths)\n","# steps \n","train_step = train_data_count//batch_size\n","test_step = test_data_count//batch_size \n","# build graph\n","with tf.Graph().as_default():\n","    # train graph\n","\tx_train, y_train = minibatch(batch_size, train_file_paths, image_size, string_length, class_count)     \n","\tlogit_train = inference(x_train, class_count, dropout = dropout, wd = wd)\n","\tcost = multi_loss(logit_train, y_train, batch_size, string_length)\n","\tupdate=parameter_update(cost,lr)\t\n","\taccuracy_train = accuracy_calc(logit_train, y_train)\n","    # test graph\n","\tx_test, y_test = minibatch(batch_size, test_file_paths, image_size, string_length, class_count)\n","\tlogit_test = inference(x_test, class_count)\n","\taccuracy_test = accuracy_calc(logit_test, y_test)  \n","\tsaver = tf.train.Saver()   \n","    # start session\n","\twith tf.Session() as sess:\n","    \t# initialize the variables\n","\t\tsess.run(tf.global_variables_initializer())\n","\t\tsess.run(tf.local_variables_initializer())\n","\t\tcoord = tf.train.Coordinator()\n","\t\tthreads = tf.train.start_queue_runners(coord=coord)      \n","    \t# restore the variables\n","\t\tif restore == True:\n","\t\t\tloader = tf.train.import_meta_graph(checkpoint_restore +'.meta')\n","\t\t\tloader.restore(sess, checkpoint_restore)       \n","\t\t# train for given number of epochs\n","\t\tfor e in range(epochs): \n","\t\t\tprint(bold + \"\\nepoch:\" + end, e)\n","\t\t\ttrain_epoch_cost = 0\n","\t\t\ttrain_epoch_acc = 0\n","\t\t\ttest_epoch_acc = 0        \n","            # train for given number of steps in one epoch\n","\t\t\tfor s in range(train_step):\n","\t\t\t\t_,train_batch_cost = sess.run([update, cost])\t          \n","\t\t\t\tif s % (train_step//2) == 0 and s != 0:\n","\t\t\t\t\tprint('~', end = '')\n","\t\t\t\telif(s == (train_step) - 1):\n","\t\t\t\t\tprint('')            \n","\t\t\t\ttrain_epoch_cost += train_batch_cost/(train_step)\t          \n","\t\t\tprint(bold + \"epoch_cost: \" + end,train_epoch_cost)       \n","            # calculate accuracy of training set\n","\t\t\tfor i in range(train_step//5):\n","\t\t\t\ttrain_epoch_acc = sess.run(accuracy_train)\n","\t\t\t\ttrain_epoch_acc += train_epoch_acc/(train_step)        \n","\t\t\tprint(bold + \"train epoch accuracy: \" + end,train_epoch_acc, \"\\n\")        \n","            # calculate accuracy on test set\n","\t\t\tfor i in range(test_step):\n","\t\t\t\ttest_epoch_acc = sess.run(accuracy_test)\n","\t\t\t\ttest_epoch_acc += test_epoch_acc/test_step    \n","\t\t\tprint(bold + \"test epoch accuracy: \" + end, test_epoch_acc, \"\\n\")       \n","            # after every x epoch decrease learning rate by factor of y (var_lr = [x, y])\n","\t\t\tif var_lr[0] != None:\n","\t\t\t\tif e%var_lr[0] == 0:\n","\t\t\t\t\tlearning_rate = learning_rate/var_lr[1]     \n","        #save all the variables\t\t\n","\t\tsave_path = saver.save(sess, checkpoint_save)\t\n","\t\tcoord.request_stop()\n","\t\tcoord.join(threads)\n","\t\tprint(\"---training over---\")"],"execution_count":null,"outputs":[]},{"metadata":{"id":"GcsdqO1cElm3","colab_type":"text"},"cell_type":"markdown","source":["### Evaluate"],"execution_count":null,"outputs":[]},{"metadata":{"id":"zjvFGVgnWO7H","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["steps=((test_data_count))//batch_size\n","accu=0\n","x_test, y_test = minibatch(batch_size, test_file_paths, image_size, string_length, class_count)\n","logit_test = inference(x_test, class_count)\n","accuracy_test = accuracy_calc(logit_test, y_test)  \n","init=tf.global_variables_initializer()\n","saver=tf.train.Saver()\n","with tf.Session() as sess:\n","\tsess.run(init)\n","\tcoord = tf.train.Coordinator()\n","\tthreads = tf.train.start_queue_runners(coord=coord)\n","\tsaver.restore(sess,checkpoint_restore)\n","\tfor s in range(steps):\n","\t\tacc=sess.run(accuracy_test)\n","\t\taccu+=acc/steps\n","\tprint(\"test set accuracy: \",acc)\n","\tcoord.request_stop()\n","\tcoord.join(threads)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"afLrhQHKDPcw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":462},"outputId":"419dbe6c-ed4b-4e89-d48e-47f8355be6f1","executionInfo":{"status":"ok","timestamp":1532017545919,"user_tz":-330,"elapsed":52902,"user":{"displayName":"Vijendra Singh","photoUrl":"//lh3.googleusercontent.com/-NdZ5dixuTHU/AAAAAAAAAAI/AAAAAAAArI4/R6qZstWMpR4/s50-c-k-no/photo.jpg","userId":"111198229299491674196"}}},"cell_type":"code","source":["all_chr = list(string.ascii_letters) + list(string.digits) + list(' ')\n","x_check, y_check=minibatch(batch_size, test_file_paths, image_size, string_length, class_count) \n","with tf.Session() as sess:\n","  sess.run(tf.global_variables_initializer())\n","  sess.run(tf.local_variables_initializer())\n","  coord = tf.train.Coordinator()\n","  threads = tf.train.start_queue_runners(coord=coord) \n","  x_c = sess.run(x_check)  \n","  eval_vizualization(x_c[1:5])\n","  coord.request_stop()\n","  coord.join(threads)"],"execution_count":null,"outputs":[]}]}