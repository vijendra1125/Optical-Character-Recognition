{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OCR using CNN.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{},"source":["# About OCR approach1:\n","Through ocr1.py script we are targeting to train a small Convolutional Neurl Network (CNN)  with the data we generated using random_string_data_gen.py. Network should be able to recognize the random string in a given image and provide it as ouput.  \n","In the first phase we will be testing it using generated data itself whereas later we try to crop some image from our screen meeting dataset contrain and see how well network works.  \n","Link to blog: https://medium.com/@vijendra1125/ocr-part-2-ocr-using-cnn-f43f0cee8016"],"execution_count":null,"outputs":[]},{"metadata":{"id":"HqYb5NXVDdSN","colab_type":"text"},"cell_type":"markdown","source":["# **Load Libraries**"],"execution_count":null,"outputs":[]},{"metadata":{"id":"SOtEHEKq_hWe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import os\n","from datetime import datetime as dt\n","import string\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["# Settings"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.set_printoptions(threshold=sys.maxsize)\n","bold = '\\033[1m'\n","end = '\\033[0m'"]},{"cell_type":"markdown","metadata":{},"source":["# Train"],"execution_count":null,"outputs":[]},{"metadata":{"id":"mpV8eHhLD3V3","colab_type":"text"},"cell_type":"markdown","source":["#### Functions"],"execution_count":null,"outputs":[]},{"metadata":{"id":"EfTGyBIhB0DO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def read_data(file_paths):\n","  '''\n","  @brief: read data from tfrecords file\n","  @args[in]:\n","    file_paths: list of path to tfrecord files\n","  @args[out]:\n","    image: an image being read from tfrecord\n","    label: a label being read from tfrecord corresponding to image\n","  '''\n","  file_queue=tf.train.string_input_producer(file_paths)\n","  feature = {'images': tf.FixedLenFeature([], tf.string),\n","             'labels': tf.FixedLenFeature([], tf.string)}    \n","  reader = tf.TFRecordReader()  \n","  _,record=reader.read(file_queue)\n","  features = tf.parse_single_example(record, features=feature)\n","  image = tf.decode_raw(features['images'], tf.uint8)\n","  label = tf.decode_raw(features['labels'], tf.uint8) \n","  return image,label\n","\n","\n","def minibatch(batch_size, \n","              file_paths, \n","              image_size, \n","              string_length, \n","              class_count):\n","  '''\n","  @brief: create minibatch of data (iamge and label)\n","  @args[in]:\n","    batch_size: size of the minibatch\n","    file_paths: list of path to the files\n","    image_size: size of the image (row, columns, channels)\n","    string_length: length of label string (including whitespace)\n","    class_count: total number of classes\n","  @args[out]:\n","    image_batch: batch of image\n","    label_batch: batch of label\n","  ''' \n","  image, label=read_data(file_paths)\n","  image = tf.cast(tf.reshape(image,image_size), dtype = tf.float32)\n","  label = tf.reshape(label, [1, string_length])\n","  label = tf.one_hot(label, class_count,axis=1)\n","  label = tf.reshape(label, tf.shape(label)[1:])\n","  image_batch,label_batch= tf.train.shuffle_batch([image, label],\n","                          batch_size, capacity, min_after_dequeue,\n","                          num_threads = num_of_threads)\n","  label_batch = tf.cast(label_batch, dtype = tf.int64)\n","  return image_batch, label_batch\n","\n","\n","def variable(name, shape, initializer, weight_decay = None):\n","  '''\n","  @brief: create parameter tensor\n","  '''\n","  var = tf.get_variable(name, shape, initializer = initializer)\n","  if weight_decay is not None:\n","    weight_loss=tf.multiply(tf.nn.l2_loss(var),weight_decay,name=\"weight_loss\")\n","    tf.add_to_collection('losses', weight_loss)\n","  return var\n","\n","\n","def conv_block(block_num,\n","               input_data,\n","               weights, \n","               weight_initializer=tf.contrib.layers.xavier_initializer(),\n","               bias_initializer=tf.constant_initializer(0.0),\n","               conv_op=[1,1,1,1],\n","               conv_padding='SAME',\n","               weight_decay=None,\n","               lrn=True,\n","               dropout=1.0, \n","               activation=True):\n","  '''\n","  @brief: convolutional block\n","  '''\n","  with tf.variable_scope('conv'+ str(block_num), reuse = tf.AUTO_REUSE) as scope:\n","    input_data = tf.nn.dropout(input_data, dropout)\n","    kernel = variable('weights', weights, initializer = weight_initializer, weight_decay = weight_decay)\n","    biases = variable('biases', weights[3], initializer=bias_initializer, weight_decay=None)\n","    conv = tf.nn.conv2d(input_data, kernel, conv_op, padding=conv_padding)\n","    pre_activation = tf.nn.bias_add(conv, biases)\n","    if lrn==True:\n","      pre_activation = tf.nn.lrn(pre_activation, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,name='norm')\n","    if activation:\n","      conv_out = tf.nn.relu(pre_activation, name=scope.name)\n","      return conv_out\n","    else:\n","      return pre_activation\n","\n","\n","def dense_block(block_num,\n","                input_data,\n","                neurons,\n","                weight_initializer=tf.contrib.layers.xavier_initializer(),\n","                bias_initializer=tf.constant_initializer(0.0),\n","                weight_decay=None,\n","                activation=True, \n","                dropout=1.0):\n","  '''\n","  @brief: Fully connected block\n","  '''\n","  with tf.variable_scope('dense'+ str(block_num), reuse = tf.AUTO_REUSE) as scope:\n","    input_data = tf.nn.dropout(input_data, dropout)\n","    weights = variable('weights', [input_data.shape[1], neurons], initializer=weight_initializer, weight_decay = weight_decay)\n","    biases = variable('biases', [1,neurons], initializer = bias_initializer, weight_decay = None)\n","    dense = tf.matmul(input_data,weights)+biases\n","    if activation:\n","      dense=tf.nn.relu(dense, name=scope.name)\n","    return dense\n","  \n","  \n","def multi_loss(logits, labels, batch_size, max_char):\n","  '''\n","  @brief: cross entopy loss for multi class\n","  '''\n","  loss = 0\n","  for i in range(max_char):\n","    loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\\\n","            (logits=logits[:,i,:],labels=labels[:,:,i]), \\\n","                           name='cross_entropy_loss_mean')\n","  loss /= max_char\n","  tf.add_to_collection('losses', loss)\n","  total_loss=tf.add_n(tf.get_collection('losses'), name='total_loss')\n","  tf.add_to_collection('losses', total_loss)\n","  return total_loss\n","\n","\n","def parameter_update(loss, learning_rate):\n","  '''\n","  @brief: optimization and parameter update using adam optimizer\n","  '''\n","  optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n","  for var in tf.trainable_variables():\n","    tf.summary.histogram(var.op.name, var)\n","  return optimizer\n","\n","\n","def accuracy_calc(output, label_batch):\n","  '''\n","  @brief: calculate accuracy\n","  '''\n","  correct_prediction = tf.equal(tf.cast(tf.argmax(output, 2),dtype=tf.int32),tf.cast(tf.argmax(label_batch, 1),dtype=tf.int32))\n","  accuracy=tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n","  return accuracy"],"execution_count":null,"outputs":[]},{"metadata":{"id":"q1gISaBjD9Yf","colab_type":"text"},"cell_type":"markdown","source":["### Model"],"execution_count":null,"outputs":[]},{"metadata":{"id":"Dx4ssU97CMm4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def inference(image_batch, class_count,\n","              dropout=[1,1,1,1],\n","              wd=None):\n","  '''\n","  @brief: define architecture using building block fuctions above\n","  '''\n","  i = 0\n","  weights=[[3,3,1,class_count//4],\n","           [3,3,class_count//4,class_count//2],\n","           [3,3,class_count//2,class_count],\n","           [3,3,class_count,class_count]]\n","  conv_op=[[1,1,1,1],[1,1,1,1],[1,1,1,1], [1,1,1,1]]\n","  \n","  conv1 = conv_block(1,image_batch,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n","  i=i+1\n","  pool1=tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1,2,2,1],padding='VALID', name='pool1') #16x128\n","  \n","  conv2 = conv_block(2,pool1,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n","  i=i+1\n","  pool2=tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1,2,2,1],padding='VALID', name='pool2') #8x64\n","  \n","  conv3 = conv_block(3,pool2,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n","  i=i+1\n","  pool3=tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1,2,2,1],padding='VALID', name='pool3') #4x32\n","  \n","  conv4 = conv_block(4,pool3,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n","  pool4=tf.nn.max_pool(conv4, ksize=[1, 4, 2, 1], strides=[1,1,2,1],padding='VALID', name='pool4') #1x16\n","  \n","  flat=tf.reshape(pool4, [tf.shape(image_batch)[0], string_length, class_count], name='flat')\n","\t\t\n","  return flat"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Parameters"],"execution_count":null,"outputs":[]},{"metadata":{"id":"y6J1kZAECcXE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["## paths ##\n","# path to folder where data (tfrecord) files has been stored\n","folder_path = \"../data\"\n","# path to load checkpoint\n","checkpoint_restore = \"../cp/ocr1_3to8\"\n","# path to save checkpoint \n","checkpoint_save = \"../cp/ocr1_3to8\"\n","\n","## data realted params ##\n","# train and test file paths\n","filenames = os.listdir(folder_path)\n","train_file_paths = []\n","test_file_paths = []\n","for filename in filenames:\n","    if \"train\" in filename:\n","        train_file_paths.append(os.path.join(folder_path, filename))\n","    elif \"test\" in filename:\n","        test_file_paths.append(os.path.join(folder_path, filename))\n","# total number of data in each train tfrecord\n","# data_per_train_file = 8192\n","total number of data in each test tfrecord\n","data_per_test_file = 2048\n","# image size\n","image_size = [32,256,1]\n","# total numember of classes\n","class_count = 63\n","# string length (including whitespace)\n","string_length = 16\n","\n","## training  setup related params ##\n","# restore from given checkpoint\n","restore = False\n","# dropout for each layer (1 means no drop)\n","dropout = [1, 1, 1, 1]\n","# weight decay\n","wd = 0.000\n","# learning rafe\n","lr = 0.01\n","# batch size\n","# batch_size = 32\n","batch_size = 1\n","# total number of epochs\n","epochs = 5\n","# after every x epoch decrease learning rate by factor of y (var_lr = [x, y])\n","var_lr=[None,None]\n","# parameters related to reading tfrecord\n","num_of_threads=16\n","min_after_dequeue=5000\n","capacity=min_after_dequeue+(num_of_threads+1)*batch_size"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Run"],"execution_count":null,"outputs":[]},{"metadata":{"id":"uXtfaRdjDOBK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":714},"outputId":"21d63f3b-80dd-4ed2-d51a-cd5e63e2cbfe","executionInfo":{"status":"ok","timestamp":1532018515949,"user_tz":-330,"elapsed":434949,"user":{"displayName":"Vijendra Singh","photoUrl":"//lh3.googleusercontent.com/-NdZ5dixuTHU/AAAAAAAAAAI/AAAAAAAArI4/R6qZstWMpR4/s50-c-k-no/photo.jpg","userId":"111198229299491674196"}}},"cell_type":"code","source":["# data count\n","train_data_count = data_per_train_file * len(train_file_paths)\n","test_data_count = data_per_test_file * len(test_file_paths)\n","# steps \n","train_step = train_data_count//batch_size\n","test_step = test_data_count//batch_size \n","# build graph\n","with tf.Graph().as_default():\n","    # train graph\n","\tx_train, y_train = minibatch(batch_size, train_file_paths, image_size, string_length, class_count)     \n","\tlogit_train = inference(x_train, class_count, dropout = dropout, wd = wd)\n","\tcost = multi_loss(logit_train, y_train, batch_size, string_length)\n","\tupdate=parameter_update(cost,lr)\t\n","\taccuracy_train = accuracy_calc(logit_train, y_train)\n","    # test graph\n","\tx_test, y_test = minibatch(batch_size, test_file_paths, image_size, string_length, class_count)\n","\tlogit_test = inference(x_test, class_count)\n","\taccuracy_test = accuracy_calc(logit_test, y_test)  \n","\tsaver = tf.train.Saver()   \n","    # start session\n","\twith tf.Session() as sess:\n","    \t# initialize the variables\n","\t\tsess.run(tf.global_variables_initializer())\n","\t\tsess.run(tf.local_variables_initializer())\n","\t\tcoord = tf.train.Coordinator()\n","\t\tthreads = tf.train.start_queue_runners(coord=coord)      \n","    \t# restore the variables\n","\t\tif restore == True:\n","\t\t\tloader = tf.train.import_meta_graph(checkpoint_restore +'.meta')\n","\t\t\tloader.restore(sess, checkpoint_restore)       \n","\t\t# train for given number of epochs\n","\t\tfor e in range(epochs): \n","\t\t\tprint(bold + \"\\nepoch:\" + end, e)\n","\t\t\ttrain_epoch_cost = 0\n","\t\t\ttrain_epoch_acc = 0\n","\t\t\ttest_epoch_acc = 0        \n","            # train for given number of steps in one epoch\n","\t\t\tfor s in range(train_step):\n","\t\t\t\t_,train_batch_cost = sess.run([update, cost])\t          \n","\t\t\t\tif s % (train_step//2) == 0 and s != 0:\n","\t\t\t\t\tprint('~', end = '')\n","\t\t\t\telif(s == (train_step) - 1):\n","\t\t\t\t\tprint('')            \n","\t\t\t\ttrain_epoch_cost += train_batch_cost/(train_step)\t          \n","\t\t\tprint(bold + \"epoch_cost: \" + end,train_epoch_cost)       \n","            # calculate accuracy of training set\n","\t\t\tfor i in range(train_step//5):\n","\t\t\t\ttrain_epoch_acc = sess.run(accuracy_train)\n","\t\t\t\ttrain_epoch_acc += train_epoch_acc/(train_step)        \n","\t\t\tprint(bold + \"train epoch accuracy: \" + end,train_epoch_acc, \"\\n\")        \n","            # calculate accuracy on test set\n","\t\t\tfor i in range(test_step):\n","\t\t\t\ttest_epoch_acc = sess.run(accuracy_test)\n","\t\t\t\ttest_epoch_acc += test_epoch_acc/test_step    \n","\t\t\tprint(bold + \"test epoch accuracy: \" + end, test_epoch_acc, \"\\n\")       \n","            # after every x epoch decrease learning rate by factor of y (var_lr = [x, y])\n","\t\t\tif var_lr[0] != None:\n","\t\t\t\tif e%var_lr[0] == 0:\n","\t\t\t\t\tlearning_rate = learning_rate/var_lr[1]     \n","        #save all the variables\t\t\n","\t\tsave_path = saver.save(sess, checkpoint_save)\t\n","\t\tcoord.request_stop()\n","\t\tcoord.join(threads)\n","\t\tprint(\"---training over---\")"],"execution_count":null,"outputs":[]},{"metadata":{"id":"GcsdqO1cElm3","colab_type":"text"},"cell_type":"markdown","source":["# **Evaluate**"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Functions"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" def decoding(encoded_data, type = 'logit'):\n","  '''\n","  @brief: decoding\n","  @args[in]:\n","  @args[out]:\n","  '''\n","  if(type == 'logit'):\n","    prediction = np.argmax(encoded_data, 2)\n","  elif(type == 'label'):\n","    prediction = np.argmax(encoded_data, 1)\n","  decoded_prediction = []\n","  for dp in prediction:\n","    predicted_text = ''\n","    for p in dp:\n","      predicted_text += all_chr[p]\n","    decoded_prediction.append(predicted_text)\n","  return decoded_prediction\n","\n","\n","def eval_vizualization(X):\n","  '''\n","  @brief:\n","  @args[in]:\n","  @args[out]:\n","  '''\n","  decoded_text = []\n","  logit = inference(X, class_count)\n","  init=tf.global_variables_initializer()\n","  saver=tf.train.Saver()\n","  \n","  with tf.Session() as sess:\n","    sess.run(init)\n","    saver.restore(sess,checkpoint_restore)\n","    text = sess.run(logit)\n","    decoded_text = decoding(text, type = 'logit')\n","  for i in range(X.shape[0]):\n","    x = np.reshape(X[i, :,:,:], image_size[0:2])\n","    plt.imshow(x, cmap = 'gray')\n","    plt.show()\n","    print(\"text: \", decoded_text[i], '<---')"]},{"cell_type":"markdown","metadata":{},"source":["### Run"],"execution_count":null,"outputs":[]},{"metadata":{"id":"zjvFGVgnWO7H","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["steps=((test_data_count))//batch_size\n","accu=0\n","x_test, y_test = minibatch(batch_size, test_file_paths, image_size, string_length, class_count)\n","logit_test = inference(x_test, class_count)\n","accuracy_test = accuracy_calc(logit_test, y_test)  \n","init=tf.global_variables_initializer()\n","saver=tf.train.Saver()\n","with tf.Session() as sess:\n","\tsess.run(init)\n","\tcoord = tf.train.Coordinator()\n","\tthreads = tf.train.start_queue_runners(coord=coord)\n","\tsaver.restore(sess,checkpoint_restore)\n","\tfor s in range(steps):\n","\t\tacc=sess.run(accuracy_test)\n","\t\taccu+=acc/steps\n","\tprint(\"test set accuracy: \",acc)\n","\tcoord.request_stop()\n","\tcoord.join(threads)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"afLrhQHKDPcw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":462},"outputId":"419dbe6c-ed4b-4e89-d48e-47f8355be6f1","executionInfo":{"status":"ok","timestamp":1532017545919,"user_tz":-330,"elapsed":52902,"user":{"displayName":"Vijendra Singh","photoUrl":"//lh3.googleusercontent.com/-NdZ5dixuTHU/AAAAAAAAAAI/AAAAAAAArI4/R6qZstWMpR4/s50-c-k-no/photo.jpg","userId":"111198229299491674196"}}},"cell_type":"code","source":["all_chr = list(string.ascii_letters) + list(string.digits) + list(' ')\n","x_check, y_check=minibatch(batch_size, test_file_paths, image_size, string_length, class_count) \n","with tf.Session() as sess:\n","  sess.run(tf.global_variables_initializer())\n","  sess.run(tf.local_variables_initializer())\n","  coord = tf.train.Coordinator()\n","  threads = tf.train.start_queue_runners(coord=coord) \n","  x_c = sess.run(x_check)  \n","  eval_vizualization(x_c[1:5])\n","  coord.request_stop()\n","  coord.join(threads)"],"execution_count":null,"outputs":[]}]}