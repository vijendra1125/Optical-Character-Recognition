{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OCR : Part 1 - Dataset Generation.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{},"source":["# About\n","In this script we will target to do following:  \n","1. generate a simpe dataset (fixed size images with random string - you will find constraints we are considering here as you read further)  \n","2. convert dataset to tfrecord format  \n","3. test the tfrecord file by reading it back and visulaizing the images from dataset  \n","\n","We are trying to keep this project simple and hence here we work with following constrains:  \n","1. white text on black background  \n","2. just using fonts available with opencv  \n","3. Max string length of 16 (includng whitespace), max character count in string of 8  \n","\n","Link to Blog: https://medium.com/@vijendra1125/ocr-part-1-generate-dataset-69509fbce9c1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["# Load libraries"],"execution_count":null,"outputs":[]},{"metadata":{"id":"CEJ9MI6FSH2I","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import os\n","import sys\n","import string\n","from datetime import datetime as dt\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Setting"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.set_printoptions(threshold=sys.maxsize)\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"]},{"metadata":{"id":"gAq_bWQwJ7X7","colab_type":"text"},"cell_type":"markdown","source":["# **Generate data**"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Functions"],"execution_count":null,"outputs":[]},{"metadata":{"id":"G54g9g58Ssb6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def gen_rand_string_data(data_count,                        \n","                         min_char_count = 3, \n","                         max_char_count = 8,\n","                         string_length = 16,\n","                         x_pos = 'side',\n","                         image_size = (32,256,1),\n","                         font = [cv2.FONT_HERSHEY_SIMPLEX], \n","                         font_scale = np.arange(0.7, 1, 0.1), \n","                         thickness = range(1, 3, 1)):\n","  '''\n","  @brief: random string data generation\n","  @args[in]:\n","    data_count: number of data sample to be genrated\n","    min_char_count: minimum number of character in a string (exclusing whitespace)\n","    max_char_count: maximum number of character in a string (excluding whitespace)\n","    string_length: maximum of number of character in string (including whitespace)\n","    x_pose: where to position string in image (\"side\" for side of image, anything else for center of image)\n","    image_size: size of data image\n","    font: lis to fonts (choosen from what available in opencv)\n","    font_scale: list of font scale/size\n","    thickness: list of font thickness\n","  @args[out]:\n","    images: all generated images\n","    labels: labels for all generated images\n","  ''' \n","  start_time=dt.now() \n","  images = []\n","  labels = []\n","  #set text color to white\n","  color = (255,255,255) \n","  # prepare the list of characters to consider\n","  char_list = list(string.ascii_letters) \\\n","              + list(string.digits) \\\n","              + list(' ')     \n","  for count in range(data_count):  \n","    for fs in font_scale:\n","      for thick in thickness:\n","        for f in font:\n","          # generate image with black background\n","          img = np.zeros(image_size, np.uint8)\n","          # generate random string within given constraint\n","          char_count = np.random.randint(min_char_count, (max_char_count + 1))\n","          rand_str = ''.join(np.random.choice(char_list, char_count))\n","          # generate image data\n","          text_size = cv2.getTextSize(rand_str, f, fs, thick)[0]  \n","          if(x_pos == 'side'):\n","            org_x = 0\n","          else:\n","            org_x = (image_size[1] - text_size[0])//2         \n","          org_y = (image_size[0] +  text_size[1])//2\n","          cv2.putText(img, rand_str, (org_x, org_y), f, fs, color, thick, cv2.LINE_AA)\n","          # prepare label\n","          label = list(rand_str) + [' '] * (string_length - len(rand_str))\n","          for i,t in enumerate(label):\n","            label[i] = char_list.index(t)           \n","          label = np.uint8(label)\n","          images.append(img)\n","          labels.append(label)        \n","  end_time = dt.now()  \n","  print(\"time taken to generate data\", end_time - start_time)          \n","  return images, labels\n","\n","\n","def _bytes_feature(value):\n","  '''\n","  @brief: function supporting write_tfrecord function below\n","  ''' \n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","\n","def write_tfrecords(images, labels, file_path):\n","  '''\n","  @brief: write data to a tfrecords file\n","  args[in]:\n","    images: all image data\n","    label: all label data\n","    file_path: path of tfrecord file in which data need to be written\n","  '''\n","  start_time=dt.now()\n","  writer = tf.python_io.TFRecordWriter(file_path)\n","  for image, label in zip(images, labels):\n","      feature = {'labels': _bytes_feature(tf.compat.as_bytes(np.array(label).tostring())),\n","                 'images': _bytes_feature(tf.compat.as_bytes(np.array(image).tostring()))}\n","      example = tf.train.Example(features=tf.train.Features(feature=feature))\n","      writer.write(example.SerializeToString())    \n","  writer.close()\n","  end_time = dt.now()  \n","  print(\"time taken to write data\", end_time - start_time)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Parameters"],"execution_count":null,"outputs":[]},{"metadata":{"id":"Kw__LAJZTk8j","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# path to folder where you could like to save the generted tfrecord data file\n","folder_path = \"data\"\n","# number of tfrecord files for rach of train and test\n","file_count = 2\n","# total number of training data per tfrecord file\n","train_data_count = 8192\n","# total number of test data per tfrecord file\n","test_data_count = 2048\n","# minimum number of characters in string (excluding whitespace)\n","min_char_count = 3\n","#maximum number of characters in string (excliuding whitespace)\n","max_char_count = 8\n","# string length (including white space)\n","string_length = 16\n","# iamge size\n","image_size = (32, 256, 1)\n","# fonts \n","font = [cv2.FONT_HERSHEY_SIMPLEX]\n","# font size\n","font_scale = np.arange(0.7, 1, 0.1) \n","# font thickness\n","thickness = range(1, 3, 1)\n","# keywork to add in file name \n","keyword = '3to8'\n","# print total data count \n","print('total train data =', file_count * train_data_count)\n","print('total test data =', file_count * test_data_count)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Run"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(file_count):\n","  train_filename = \"train_{key}_{idx}.tfrecords\".format(key = keyword, idx = i+1)\n","  test_filename = \"test_{key}_{idx}.tfrecords\".format(key = keyword, idx = i+1)\n","  train_file_path = os.path.join(folder_path, train_filename)\n","  test_file_path = os.path.join(folder_path, test_filename)\n","  # train data\n","  print('generating train file number {idx}'.format(idx = i+1))\n","  images, labels = gen_rand_string_data(data_count = train_data_count,\n","                                        min_char_count = min_char_count,\n","                                        max_char_count = max_char_count, \n","                                        string_length = string_length,\n","                                        image_size = image_size,\n","                                        font = font,\n","                                        font_scale = font_scale,\n","                                        thickness = thickness)\n","  write_tfrecords(images, labels, train_file_path)                     \n","  print('train file number {idx} generated'.format(idx = i+1))\n","  # test data\n","  print('generating test file number {idx}'.format(idx = i+1))\n","  images, labels = gen_rand_string_data(data_count = test_data_count,\n","                                        min_char_count = min_char_count,\n","                                        max_char_count = max_char_count, \n","                                        string_length = string_length,\n","                                        image_size = image_size,\n","                                        font = font,\n","                                        font_scale = font_scale,\n","                                        thickness = thickness)\n","  write_tfrecords(images, labels, test_file_path)\n","  print('test file number {idx} generated'.format(idx = i+1))"]},{"metadata":{"id":"n9pK9nVEJ3pN","colab_type":"text"},"cell_type":"markdown","source":["# **Check generated data**"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Functions"],"execution_count":null,"outputs":[]},{"metadata":{"id":"Vw5kWWIlWNx_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def read_data(file_paths):\n","  '''\n","  @brief: read data from tfrecords file\n","  @args[in]:\n","    file_paths: list of path to tfrecord files\n","  @args[out]:\n","    image: an image being read from tfrecord\n","    label: a label being read from tfrecord corresponding to image\n","  '''\n","  file_queue=tf.train.string_input_producer(file_paths)\n","  feature = {'images': tf.FixedLenFeature([], tf.string),\n","             'labels': tf.FixedLenFeature([], tf.string)}    \n","  reader = tf.TFRecordReader()  \n","  _,record=reader.read(file_queue)\n","  features = tf.parse_single_example(record, features=feature)\n","  image = tf.decode_raw(features['images'], tf.uint8)\n","  label = tf.decode_raw(features['labels'], tf.uint8) \n","  return image,label\n","\n","\n","def minibatch(batch_size, \n","              file_paths, \n","              image_size, \n","              string_length, \n","              class_count):\n","  '''\n","  @brief: create minibatch of data (iamge and label)\n","  @args[in]:\n","    batch_size: size of the minibatch\n","    file_paths: list of path to the files\n","    image_size: size of the image (row, columns, channels)\n","    string_length: length of label string (including whitespace)\n","    class_count: total number of classes\n","  @args[out]:\n","    image_batch: batch of image\n","    label_batch: batch of label\n","  ''' \n","  image, label=read_data(file_paths)\n","  image = tf.cast(tf.reshape(image,image_size), dtype = tf.float32)\n","  label = tf.reshape(label, [1, string_length])\n","  label = tf.one_hot(label, class_count,axis=1)\n","  label = tf.reshape(label, tf.shape(label)[1:])\n","  image_batch,label_batch= tf.train.shuffle_batch([image, label],\n","                          batch_size, capacity, min_after_dequeue,\n","                          num_threads = num_of_threads)\n","  label_batch = tf.cast(label_batch, dtype = tf.int64)\n","  return image_batch, label_batch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Parameters"],"execution_count":null,"outputs":[]},{"metadata":{"id":"6o0MPS6xcHkj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# path to folder where tfrecord files has been stored\n","folder_path = \"data\"\n","# tfrecord file paths\n","file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)]\n","# size on image in dataset\n","image_size = [32,256,1]\n","# length of labeled string\n","string_length = 16\n","# total number sof classes ( total number of characters considered here)\n","class_count = 63\n","# size of minibatch you want to read\n","batch_size = 32\n","# number of images to visualize\n","vis_image_count = 5\n","# if true show one hot encoded label\n","show_label = False\n","# parameters related to reading tfrecord\n","num_of_threads = 16\n","min_after_dequeue = 5000\n","capacity=min_after_dequeue+(num_of_threads+1)*batch_size"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Run"],"execution_count":null,"outputs":[]},{"metadata":{"id":"e9otcxEa2Yt0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.Graph().as_default():\n","  image_batch, label_batch=minibatch(batch_size, file_paths, image_size, string_length, class_count)\n","  init=tf.global_variables_initializer()\n","  with tf.Session() as sess:\n","    sess.run(init)\n","    sess.run(tf.local_variables_initializer())\n","    coord = tf.train.Coordinator()\n","    threads = tf.train.start_queue_runners(coord=coord) \n","    for i in range(vis_image_count):\n","      image_b, label_b= sess.run([image_batch, label_batch])\n","      if(i == 0):\n","        print('data type of image:', type(image_b[0][0,0,0]))\n","        print('data type of label:', type(label_b[0][0,0]))\n","        print(\"shape of image_batch:\", image_b.shape)\n","        print('shape of label_out:', label_b.shape)\n","      plt.imshow(np.reshape(image_b[0],[32,256]), cmap = 'gray')\n","      plt.show()\n","      if(show_label):\n","        print(sess.run(tf.transpose(label_b[0])))\n","    coord.request_stop()\n","    coord.join(threads)"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}